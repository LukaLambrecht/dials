# Notes
#
# 1. This docker-compose is not production-ready, you should use it only for development puporses
#    if do not want to run the entire stack natively
#
# 2. This file assumes that PostgreSQL and Redis are running as standalone docker containers
#    as describe in backend's README, so we need to set network_mode to "host"
#    in any application that need to communicate with those containers.
#    Optionally you can modified it yourself an run PostgresSQL and Redis from it and remove the network_mode
#    but make sure to expose all the necessary ports and check the links between containers
#
# 3. This file also assumes that DQMIO files are stored under the path "/mnt/dqmio" in the host
#    you can modify this location as you wish, remember to also modify the path in .env
#    if the application is also going to look for the files anywhere else

version: '3'

services:
  celery_beat_dev:
    container_name: celery_beat_dev
    image: backend_dev
    volumes:
      - ./backend/:/home/app/rest_api
      - /mnt/dqmio:/mnt/dqmio
    command: bash -c 'celery --app=dials beat --loglevel=INFO --schedule=celerybeat-schedule'
    network_mode: "host"

  celery_worker_periodic_dev:
    container_name: celery_worker_periodic_dev
    image: backend_dev
    volumes:
      - ./backend/:/home/app/rest_api
      - /mnt/dqmio:/mnt/dqmio
    command: bash -c 'celery --app=dials worker --loglevel=INFO --concurrency=2 --autoscale=4,2 --max-tasks-per-child=1 --hostname=periodic_worker --queues=periodic_scheduler'
    network_mode: "host"

  celery_worker_indexer_dev:
    container_name: celery_worker_indexer_dev
    image: backend_dev
    volumes:
      - ./backend/:/home/app/rest_api
      - /mnt/dqmio:/mnt/dqmio
    command: bash -c 'celery --app=dials worker --loglevel=INFO --concurrency=1 --autoscale=1,0 --max-tasks-per-child=1 --hostname=indexer_worker --queues=etl_file_indexer'
    network_mode: "host"

  celery_worker_bulk_dev:
    container_name: celery_worker_bulk_dev
    image: backend_dev
    volumes:
      - ./backend/:/home/app/rest_api
      - /mnt/dqmio:/mnt/dqmio
    command: bash -c 'celery --app=dials worker --loglevel=INFO --concurrency=1 --autoscale=2,0 --max-tasks-per-child=1 --hostname=etl_bulk_worker --queues=etl_bulk_ingestion'
    network_mode: "host"

  celery_worker_priority_dev:
    container_name: celery_worker_priority_dev
    image: backend_dev
    volumes:
      - ./backend/:/home/app/rest_api
      - /mnt/dqmio:/mnt/dqmio
    command: bash -c 'celery --app=dials worker --loglevel=INFO --concurrency=1 --autoscale=2,0 --max-tasks-per-child=1 --hostname=etl_priority_worker --queues=etl_priority_ingestion'
    network_mode: "host"

  django_restapi_dev:
    container_name: django_restapi_dev
    image: backend_dev
    build:
      dockerfile: backend/Dockerfile
      context: .
      args:
        - UID
        - GID
    volumes:
      - ./backend/:/home/app/rest_api
      - /mnt/dqmio:/mnt/dqmio
    command: bash -c 'python3 manage.py runserver 0.0.0.0:8000'
    network_mode: "host"

  frontend_dev:
    container_name: frontend_dev
    image: frontend_dev
    build:
      dockerfile: frontend/Dockerfile
      context: .
      args:
        - UID
        - GID
    volumes:
      - ./frontend/:/home/app/web/frontend
    network_mode: "host"
